model: MLP
model_cfg: configs/models/MLP.yaml
save_dir:

num_classes: 10
dataset: cifar10
data_root: datasets/cifar10
data_trans: sifar10_mlp
num_workers: 8

train:
  enable: True
  pretrained: False
  optimizer: SGD
  optim_params:
    lr: 0.01
    momentum: 0.9
    weight_decay: 5e-4

  scheduler: CosineAnnealingLR
  scheduler_params:
    T_max: 50

  loss: crossentropyloss
  epochs: 50
  batchsize: 128
  resume: False
  resume_path: 'checkpoints/cifar10/resnet50/last.pth'

val:
  enable: False

test:
  enable: False